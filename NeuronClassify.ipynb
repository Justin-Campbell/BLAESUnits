{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLAES Units E/I Neuron Classification\n",
    "\n",
    "This notebook contains code for classifying neuron cell type based on properties of the waveform.\n",
    "\n",
    "---\n",
    "\n",
    "> *Contact: Justin Campbell (justin.campbell@hsc.utah.edu)*  \n",
    "> *Version: 05/27/2025*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec as gs\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import chi2_contingency, mannwhitneyu\n",
    "\n",
    "%config InlineBackend.figure_format='retina'\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load & Organize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "projDir = '/Users/justincampbell/Library/CloudStorage/GoogleDrive-u0815766@gcloud.utah.edu/My Drive/Research Projects/BLAESUnits/'\n",
    "resultsDir = os.path.join(projDir, 'Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Waveforms and Events, create a dictionary for each session with the waveforms for each unit\n",
    "wf_dict = {}\n",
    "sessions = [x for x in os.listdir(resultsDir) if os.path.isdir(os.path.join(resultsDir, x)) and x != 'Group']\n",
    "for session in sessions:\n",
    "    session_dict = {}\n",
    "    wfs = pd.read_csv(os.path.join(resultsDir, session, 'Waveforms.csv'), index_col = 0)\n",
    "    events = pd.read_csv(os.path.join(resultsDir, session, 'Events.csv'), index_col = 0)\n",
    "    events['Chan-Unit'] = events['Channel'].astype(str) + '-' + events['Unit'].astype(str)\n",
    "    units = events['Chan-Unit'].unique()\n",
    "    for unit in units:\n",
    "        unit_events = events[events['Chan-Unit'] == unit].index\n",
    "        unit_wfs = wfs.loc[unit_events].reset_index(drop = True)\n",
    "        session_dict[unit] = unit_wfs\n",
    "    wf_dict[session] = session_dict\n",
    "    \n",
    "    \n",
    "# Loads spike stats\n",
    "spike_stats = pd.read_csv(os.path.join(resultsDir, 'Group', 'SpikeStats.csv'), index_col = 0)\n",
    "spike_stats = spike_stats[spike_stats['Valid'] == True] # Filter out invalid units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Waveform Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WFFeats(session, unit, wfs, export = False, show = False):\n",
    "    '''Calculate and plot waveform features for a given session and unit.\n",
    "    \n",
    "    - Parameters:\n",
    "        session (str): Session identifier (e.g., 'BJH-2023-01-01').\n",
    "        unit (str): Unit identifier (e.g., 'LAMY4-1').\n",
    "        wfs (pd.DataFrame): DataFrame containing waveforms for the specified unit.\n",
    "        export (bool): If True, export the figure as a PDF.\n",
    "        show (bool): If True, display the figure.\n",
    "        \n",
    "    - Returns:\n",
    "        pd.DataFrame: DataFrame containing waveform features including Peak, Trough, Valley-to-Peak (VP), Peak Half Width (PeakHW), number of spikes (NSpikes), and Validity (â‰¥ FR threshold).\n",
    "    '''\n",
    "\n",
    "    f_type = session[0:3]\n",
    "    # Get features\n",
    "    wf_avg = wfs.mean(axis = 0)\n",
    "    peak = wf_avg.idxmax()\n",
    "    trough = wf_avg.idxmin()\n",
    "    half_peak = wf_avg[peak] / 2\n",
    "    diffs_idxs = np.abs(wf_avg - half_peak).sort_values()\n",
    "    hp_idx1 = diffs_idxs[diffs_idxs.index < peak].index[0]\n",
    "    hp_idx2 = diffs_idxs[diffs_idxs.index > peak].index[0]\n",
    "    vp = abs(int(trough) - int(peak)) / 30000 * 1000 # convert to ms\n",
    "    phw = abs(int(hp_idx2) - int(hp_idx1)) / 30000 * 1000 # convert to ms\n",
    "    validity = spike_stats[(spike_stats['pID'] == session) & (spike_stats['Unit'] == unit)]['Valid'].values[0]\n",
    "\n",
    "    if show or export:\n",
    "\n",
    "        # Setup figure\n",
    "        fig, ax = plt.subplots(figsize = (3, 2))\n",
    "        feat_colors = sns.color_palette('Set1', 4)\n",
    "\n",
    "        # Plot waveforms\n",
    "        for i in range(wfs.shape[0]):\n",
    "            plt.plot(wfs.iloc[i,:], color = '#e4e4e4', alpha = 0.25, lw = 1)\n",
    "        plt.plot(wf_avg, color = 'k', linewidth = 4)\n",
    "\n",
    "        # Plot features\n",
    "        plt.scatter(peak, wf_avg[peak], color = feat_colors[0], s = 30, label = 'Peak', zorder = 100)\n",
    "        plt.scatter(trough, wf_avg[trough], color = feat_colors[1], s = 30, label = 'Trough', zorder = 100)\n",
    "        plt.plot([trough, peak], [wf_avg[peak], wf_avg[peak]], color = feat_colors[3], linestyle = '--')\n",
    "        plt.plot([trough, trough], [wf_avg[trough], wf_avg[peak]], color = feat_colors[3], linestyle = '--', label = 'Valley-to-Peak')\n",
    "        plt.plot([hp_idx1, hp_idx2], [wf_avg[hp_idx1], wf_avg[hp_idx2]], color = feat_colors[2], linestyle = '--', marker = 'o', markersize = 6, label = 'Peak Half Width')\n",
    "\n",
    "        # Figure aesthetics\n",
    "        plt.title(session + ', ' + unit, pad = 15, fontsize = 'large')\n",
    "        plt.xlabel('Time (ms)', fontsize = 'large')\n",
    "        plt.ylabel('Voltage ($\\\\mu$V)', fontsize = 'large')\n",
    "        if f_type == 'BJH':\n",
    "            tick_range = np.arange(0, 31, 15)\n",
    "            time = tick_range / 30000 * 1000\n",
    "            plt.xticks(tick_range, time)\n",
    "            plt.xlim(0, 31)\n",
    "        elif f_type == 'UIC':\n",
    "            tick_range = np.arange(0, 46, 15)\n",
    "            time = tick_range / 30000 * 1000\n",
    "            plt.xticks(tick_range, time)\n",
    "            plt.xlim(0, 48)\n",
    "        sns.despine(top = True, right = True)\n",
    "        handles, _ = plt.gca().get_legend_handles_labels()\n",
    "        handles.append(Rectangle((0,0),1,1,fc=\"#e4e4e4\", fill=True, edgecolor='none', linewidth=0))\n",
    "        handles.append(Rectangle((0,0),1,1,fc=\"w\", fill=False, edgecolor='none', linewidth=0))\n",
    "        labels = ['Peak: %.1f $\\\\mu$V' %wf_avg[peak], 'Trough: %.1f $\\\\mu$V' %wf_avg[trough], 'V-P: %.2f ms' %vp, 'P$_{HW}$: %.2f ms' %phw, 'Spikes: %i' %wfs.shape[0], 'FR Valid: %s' %validity]\n",
    "        plt.legend(handles, labels, title = 'WF Features', title_fontsize = 'small', fontsize = 'x-small', bbox_to_anchor = (1.05, 1))\n",
    "\n",
    "        # Export & Display\n",
    "        if export:\n",
    "            plt.savefig('/Users/justincampbell/Desktop/TEST.pdf', dpi = 1200, bbox_inches = 'tight')\n",
    "        if show:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    return pd.DataFrame({'pID': session, 'Unit': unit, 'Peak': peak, 'Trough': trough, 'VP': vp, 'PeakHW': phw, 'NSpikes': wfs.shape[0], 'Valid': validity}, index = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dfs = []\n",
    "\n",
    "for session in spike_stats['pID'].unique():\n",
    "    for unit in spike_stats[spike_stats['pID'] == session]['Unit'].unique():\n",
    "        wfs = wf_dict[session][unit]\n",
    "        df = WFFeats(session, unit, wfs, export = False, show = False)\n",
    "        feature_dfs.append(df)\n",
    "        \n",
    "feature_df = pd.concat(feature_dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Means Clustering\n",
    "Methods based on [Peyrache et al. 2011, *PNAS*](https://www.pnas.org/doi/full/10.1073/pnas.1109895109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do k-means clustering using the PHW and VP features\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "feature_df['Cluster'] = kmeans.fit_predict(feature_df[['PeakHW', 'VP']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the spike stats DataFrame\n",
    "spike_stats_clust = spike_stats.merge(feature_df[['pID', 'Unit', 'Cluster']], on=['pID', 'Unit'], how='left')\n",
    "\n",
    "# Isolate the two clusters\n",
    "df_e = spike_stats_clust[spike_stats_clust['Cluster'] == 0]\n",
    "df_i = spike_stats_clust[spike_stats_clust['Cluster'] == 1]\n",
    "e_pct = spike_stats_clust[spike_stats_clust['Cluster'] == 0].shape[0] / spike_stats_clust.shape[0] * 100\n",
    "i_pct = spike_stats_clust[spike_stats_clust['Cluster'] == 1].shape[0] / spike_stats_clust.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of E and I units\n",
    "print(f'Excitatory units: {df_e.shape[0]} ({e_pct:.1f}%)')\n",
    "print(f'Inhibitory units: {df_i.shape[0]} ({i_pct:.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X,Y position of cluster centroids\n",
    "centroids = kmeans.cluster_centers_\n",
    "centroid_df = pd.DataFrame(centroids, columns=['PeakHW', 'VP'])\n",
    "centroid_df['Cluster'] = ['E', 'I']\n",
    "centroid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotOrder = spike_stats_clust['Region'].value_counts().index\n",
    "palette = ['#6d9dc5', '#ff6e61']\n",
    "sns.palplot(palette, size = 0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gridspec to create a 2x2 grid of subplots\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "gs = fig.add_gridspec(3, 2, width_ratios=[1, 2], height_ratios=[1, 1, 1])\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "ax2 = fig.add_subplot(gs[1:, 0])\n",
    "ax3 = fig.add_subplot(gs[:, 1])\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.25)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "ex_session = ['UIC20221701', 'UIC20230701']\n",
    "ex_units = ['mLOFC3-1', 'mLHC7-1']\n",
    "\n",
    "for i in range(2):\n",
    "    session = ex_session[i]\n",
    "    unit = ex_units[i]\n",
    "    f_type = session[0:3]\n",
    "    wfs = wf_dict[session][unit]\n",
    "    wf_avg = wfs.mean(axis=0)\n",
    "    melted_wfs = wfs.melt(var_name='Time', value_name='Voltage')\n",
    "    sns.lineplot(data=melted_wfs, x='Time', y='Voltage', ax=ax2, lw=4, color = palette[i], errorbar = 'sd')\n",
    "    # wf_avg = wfs.mean(axis = 0)\n",
    "    # # Plot WFs\n",
    "    # for ii in range(wfs.shape[0]):\n",
    "    #     ax2.plot(wfs.iloc[ii,:], color = '#e4e4e4', alpha = 0.1, lw = 1)\n",
    "    # ax2.plot(wf_avg, color = palette[i], linewidth = 4)\n",
    "\n",
    "ax1.plot(wf_avg, color = '#7E7E7E', linewidth = 3)\n",
    "trough = wf_avg.idxmin()\n",
    "peak = wf_avg.idxmax()\n",
    "half_peak = wf_avg[peak] / 2\n",
    "diffs_idxs = np.abs(wf_avg - half_peak).sort_values()\n",
    "hp_idx1 = diffs_idxs[diffs_idxs.index < peak].index[0]\n",
    "hp_idx2 = diffs_idxs[diffs_idxs.index > peak].index[0]\n",
    "ax1.scatter(peak, wf_avg[peak], color = 'k', s = 10, label = 'Peak', zorder = 100)\n",
    "ax1.scatter(trough, wf_avg[trough], color = 'k', s = 10, label = 'Trough', zorder = 100)\n",
    "ax1.plot([trough, peak], [wf_avg[peak], wf_avg[peak]], color = 'k', linestyle = ':', lw = 1)\n",
    "ax1.plot([trough, trough], [wf_avg[trough], wf_avg[peak]], color = 'k', linestyle = ':', label = 'Valley-to-Peak', lw = 1)\n",
    "ax1.plot([hp_idx1, hp_idx2], [wf_avg[hp_idx1], wf_avg[hp_idx2]], color = 'k', linestyle = ':', lw = 1, marker = 'o', markersize = 3, label = 'Peak Half Width')\n",
    "\n",
    "# Add text annotations for PHW and VP\n",
    "ax1.text(0.45, 0.35, 'PHW', transform=ax1.transAxes, fontsize='small', ha='center')\n",
    "ax1.text(0.25, 0.725, 'VP', transform=ax1.transAxes, fontsize='small', ha='center')\n",
    "    \n",
    "sns.scatterplot(data=feature_df, x='PeakHW', y='VP', ax=ax3, hue = 'Cluster', palette = palette, s=50, alpha = 0.75)\n",
    "ex1_df = feature_df[(feature_df['pID'] == ex_session[0]) & (feature_df['Unit'] == ex_units[0])]\n",
    "ex2_df = feature_df[(feature_df['pID'] == ex_session[1]) & (feature_df['Unit'] == ex_units[1])]\n",
    "sns.scatterplot(data=ex1_df, x='PeakHW', y='VP', ax=ax3, color=palette[0], s=50, edgecolor='k', linewidth=1)\n",
    "sns.scatterplot(data=ex2_df, x='PeakHW', y='VP', ax=ax3, color=palette[1], s=50, edgecolor='k', linewidth=1)\n",
    "\n",
    "# Add marginal plots\n",
    "\n",
    "# Aesthetics\n",
    "sns.despine(ax=ax1, top=True, right=True, left=True, bottom=True)\n",
    "ax1.set_ylim(-100, 100)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "sns.despine(ax = ax2, top = True, right = True)\n",
    "ax2.set_xlim(0, 45)\n",
    "ax2.set_ylim(-100, 50)\n",
    "ax2.set_yticks(np.arange(-100, 51, 50), ['-100', '-50', '0', '50'], fontsize='medium')\n",
    "ax2.set_xlabel('Time (ms)', fontsize='large', labelpad=10)\n",
    "ax2.set_ylabel('Voltage ($\\\\mu$V)', fontsize='large', labelpad=10)\n",
    "if f_type == 'BJH':\n",
    "    tick_range = np.arange(0, 31, 15)\n",
    "    time = tick_range / 30000 * 1000\n",
    "    ax2.set_xticks(tick_range, time)\n",
    "elif f_type == 'UIC':\n",
    "    tick_range = np.arange(0, 46, 15)\n",
    "    time = tick_range / 30000 * 1000\n",
    "    ax2.set_xticks(tick_range, time)\n",
    "\n",
    "sns.despine(ax = ax3, top = True, right = True)\n",
    "ax3.set_xlim(0, 0.9)\n",
    "ax3.set_ylim(0, 0.9)\n",
    "ax3.set_xticks(np.arange(0, 1.2, 0.3), ['0', '0.3', '0.6', '0.9'], fontsize='medium')\n",
    "ax3.set_yticks(np.arange(0, 1.2, 0.3), ['0', '0.3', '0.6', '0.9'], fontsize='medium')\n",
    "ax3.set_xlabel('Peak Half Width (ms)', fontsize='large', labelpad=10)\n",
    "ax3.set_ylabel('Valley-to-Peak (ms)', fontsize='large', labelpad=10)\n",
    "handles, labels = ax3.get_legend_handles_labels()\n",
    "labels = ['E (%.1f%%)' % (e_pct), 'I (%.1f%%)' % (i_pct)]\n",
    "for handle in handles:\n",
    "    handle.set_alpha(1)\n",
    "ax3.legend(title='Cluster', handles = handles, labels = labels, title_fontsize='medium', fontsize='small', loc = 'upper left')\n",
    "\n",
    "\n",
    "plt.savefig((os.path.join(resultsDir, 'Group', 'Figures', 'EIWFs.pdf')), dpi = 1200, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created separately to paste over the scatter plot above (cannot use jointplot with axes)\n",
    "sns.jointplot(data=feature_df, x='PeakHW', y='VP', hue='Cluster', palette=palette, alpha=0.75, height=5, marginal_kws={'common_norm': False}, s = 50)\n",
    "\n",
    "ex1_df = feature_df[(feature_df['pID'] == ex_session[0]) & (feature_df['Unit'] == ex_units[0])]\n",
    "ex2_df = feature_df[(feature_df['pID'] == ex_session[1]) & (feature_df['Unit'] == ex_units[1])]\n",
    "\n",
    "# get the count of overlapping points\n",
    "\n",
    "sns.scatterplot(data=ex1_df, x='PeakHW', y='VP', color=palette[0], s=50, edgecolor='k', linewidth=1)\n",
    "sns.scatterplot(data=ex2_df, x='PeakHW', y='VP', color=palette[1], s=50, edgecolor='k', linewidth=1)\n",
    "\n",
    "# resize figure\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(4.5, 3)\n",
    "\n",
    "sns.despine(ax = ax3, top = True, right = True)\n",
    "plt.xlim(0, 0.9)\n",
    "plt.ylim(0, 0.9)\n",
    "plt.xticks(np.arange(0, 1.2, 0.3), ['0', '0.3', '0.6', '0.9'], fontsize='medium')\n",
    "plt.yticks(np.arange(0, 1.2, 0.3), ['0', '0.3', '0.6', '0.9'], fontsize='medium')\n",
    "plt.xlabel('Peak Half Width (ms)', fontsize='large', labelpad=10)\n",
    "plt.ylabel('Valley-to-Peak (ms)', fontsize='large', labelpad=10)\n",
    "handles, labels = ax3.get_legend_handles_labels()\n",
    "labels = ['E (%.1f%%)' % (e_pct), 'I (%.1f%%)' % (i_pct)]\n",
    "for handle in handles:\n",
    "    handle.set_alpha(1)\n",
    "plt.legend(title='Cluster', handles = handles, labels = labels, title_fontsize='medium', fontsize='small', loc = 'upper left')\n",
    "\n",
    "plt.savefig((os.path.join(resultsDir, 'Group', 'Figures', 'EIWScatterV2.pdf')), dpi = 1200, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (1, 2), sharey = True)\n",
    "\n",
    "# Parse data, convert to percentage\n",
    "mod_e_pct = 100 * df_e['StimSig'].mean()\n",
    "mod_i_pct = 100 * df_i['StimSig'].mean()\n",
    "\n",
    "# Create barplot\n",
    "sns.barplot([mod_e_pct, mod_i_pct], palette = palette, saturation = 0.8)\n",
    "\n",
    "# Figure aeshtetics\n",
    "plt.setp(ax.patches, linewidth = 0.5, edgecolor = 'k')\n",
    "ax.set_ylabel('% Modulated Units', fontsize = 'large', labelpad = 10)\n",
    "tick_spacing = 9\n",
    "yticks = np.arange(0, 36 + .1, tick_spacing)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_xticks([0, 1], ['E', 'I'])\n",
    "ax.set_ylim(0, yticks[-1])\n",
    "ax.set_xlabel('Cluster', fontsize = 'large', labelpad = 10)\n",
    "sns.despine(top = True, right = True)\n",
    "\n",
    "plt.savefig((os.path.join(resultsDir, 'Group', 'Figures', 'EIModulation.pdf')), dpi = 1200, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "# Do a chi-square test for the two clusters\n",
    "contingency_table = pd.crosstab(spike_stats_clust['Cluster'], spike_stats_clust['StimSig'])\n",
    "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-square test results:\\nChi2: {chi2:.2f}, p-value: {p:.4f}, DF: {dof}\")\n",
    "\n",
    "# Print percentage of modulated units in each cluster\n",
    "mod_e_pct = 100 * df_e['StimSig'].mean()\n",
    "mod_i_pct = 100 * df_i['StimSig'].mean()\n",
    "print(f\"Percentage of modulated units in E cluster: {mod_e_pct:.1f}%\")\n",
    "print(f\"Percentage of modulated units in I cluster: {mod_i_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (2.5, 2))\n",
    "sns.countplot(x = 'Region', data = spike_stats_clust, order = plotOrder, color = palette[0])\n",
    "sns.countplot(x = 'Region', data = spike_stats_clust[spike_stats_clust['Cluster'] == 1], order = plotOrder, color = palette[1])\n",
    "e_pct = spike_stats_clust[spike_stats_clust['Cluster'] == 0].shape[0] / spike_stats_clust.shape[0] * 100\n",
    "i_pct = spike_stats_clust[spike_stats_clust['Cluster'] == 1].shape[0] / spike_stats_clust.shape[0] * 100\n",
    "\n",
    "# Figure aeshtetics\n",
    "plt.setp(ax.patches, linewidth = 0.5, edgecolor = 'k')\n",
    "plt.legend(title = 'Cluster', labels = ['E', 'I'], title_fontsize = 'medium', fontsize = 'small', bbox_to_anchor = (1, 1))\n",
    "ax.set_xlabel('Region', fontsize = 'large', labelpad = 10)\n",
    "ax.set_ylabel('# Units', fontsize = 'large', labelpad = 10)\n",
    "ax.set_yticks(np.arange(0, 91, 30), ['0', '30', '60', '90'], fontsize='medium')\n",
    "ax.set_ylim(0, 90)\n",
    "sns.despine(top = True, right = True)\n",
    "\n",
    "plt.savefig((os.path.join(resultsDir, 'Group', 'Figures', 'EIRegion.pdf')), dpi = 1200, bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (1, 2))\n",
    "\n",
    "# Parse data, convert to percentage\n",
    "sns.boxplot(x = 'Cluster', y = 'FR_ISI', hue = 'Cluster', data = spike_stats_clust, ax = ax, palette = palette, saturation = 0.8, legend = False, linecolor = 'k', width = 0.75, fliersize=2.5)\n",
    "\n",
    "# Aesthetics\n",
    "sns.despine(top = True, right = True)\n",
    "ax.set_xlabel('Cluster', fontsize = 'large', labelpad = 10)\n",
    "ax.set_ylabel('Baseline FR (Hz)', fontsize = 'large', labelpad = 10)\n",
    "ax.set_xticks([0, 1], ['E', 'I'], fontsize='medium')\n",
    "ax.set_yticks(np.arange(0, 21, 5), ['0', '5', '10', '15', '20'], fontsize='medium')\n",
    "ax.set_ylim(0, 20)\n",
    "\n",
    "plt.savefig((os.path.join(resultsDir, 'Group', 'Figures', 'EIFR.pdf')), dpi = 1200, bbox_inches = 'tight')\n",
    "plt.show()\n",
    "\n",
    "# Do a Mann-Whitney U test for the two clusters\n",
    "e, p_value = mannwhitneyu(df_e['FR_ISI'], df_i['FR_ISI'])\n",
    "print(f\"Mann-Whitney U test results:\\nU-statistic: {e:.2f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
